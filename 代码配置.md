# 基于HA-DPO和LLaVA的代码库进行训练和测试

快速预览 `ctrl + shift + v`

## conda环境搭建

参考[环境配置](/home/cuiruochen/环境配置.md)完成conda环境搭建与配置, 使用以下代码使用环境

```
conda activate hadpo
```

## git版本管理

**_step1._** vscode 安装 git 相关插件

**_step2._** 用户登录 github 账号

1. 用户账号的主目录下生成 ssh 密钥对

```
ssh-keygen -t rsa -b 4096 -C "your_email@example.com"
```

打开生成的公钥文件, 它的默认位置是 `~/.ssh/id_rsa.pub`, 复制公钥内容. 然后登录 GitHub, 转到 "Settings" -> "SSH and GPG keys" -> "New SSH key", 将公钥粘贴到 "Key" 文本框中, 然后点击 "Add SSH key"

2. 在项目文件夹路径下登录账号 (**note**: 这里没有使用--global, 使用的后果未知)

```
git config --global user.name "Your Name"
git config --global user.email "your_email@example.com"
git config --global core.sshCommand "ssh -i /home/user1/.ssh/id_rsa"
```

确保将 `/home/user1/.ssh/id_rsa` 替换为你生成的私钥的路径

3. 尝试连接github

```
ssh -T git@github.com
```

确认连接后, 会提示 "You've successfully authenticated", 表示登陆成功


**_step3._** 将服务器仓库与远程仓库关联

```
git remote add origin https://github.com/421zuoduan/Deep-Learning-for-MLLMs.git
```

如果已经与远程仓库关联, 使用以下指令查看当前关联的远程仓库

```
git remote -v
```

与原有远程仓库删除关联

```
git remote remove origin
```

此时再执行前述关联新仓库的指令


**_step4._** 设置.gitignore

`.gitignore` 文件用以设置哪些文件夹和文件不需要上传, 具体格式详见该文件


**_step4._** git push

创建测试环境分支 `dev`, 并在服务器上切换为该分支

```
git checkout -b dev
```

由于本地是 git clone 自HA-DPO仓库并进行了修改, 这里不进行 git pull 操作, 强制 push

```
git add .
git commit -m "init"
git push origin dev --force
```

push 过程中经常出现网络连接问题, 尝试使用以下代码取消代理. 如果依然出现 fatal 报错, 等一会再push

```
git config --global --unset http.proxy
git config --global --unset https.proxy
```

经常出现的报错有:

```
fatal: unable to access 'https://github.com/user/project.git/': GnuTLS recv error (-110): The TLS connection was non-properly terminated.
```

或

```
fatal: unable to access 'https://github.com/user/project.git/': Failed to connect to github.com port 443 after 131081 ms: Connection timed out
```


**_step5._** commit 的撤销与删除

commit时如果发现有时间过长或大文件没有gitignore, 可以使用插件`Git Graph`撤销commit

| | 是否删除对代码的修改 | 是否删除commit记录 | 是否新增commit记录 |
|:--:|:--:|:--:|:--:|
| Undo Commit | 不会 | 未Push会, 已Push不会 | 不会 |
| Revert Commit | 会 | 不会 | 会 |
| Drop Commit | 会 | 未Push会, 已Push不会 | 不会 |

按下`Ctrl + Shift + P`, 然后搜索`Git: Undo Last Commit`, 即可撤销上一次的commit

**_step6._** 大文件push后无法解决之究极方法--删除repo和.git文件

1. 删repo

2. 打开vscode的 `File-Preferences-Setting`, 搜索 `Exclude`, 删除 `**/.git`, 即可显示 `.git` 文件夹, 删除.git

3. 从用户登录处重新操作

## 数据集与代码准备

### 数据集准备

依照 [data preparation](ha_dpo/data/data_preparation.md) 进行数据集和测试集的准备

数据集结构如下

```
ha_dpo/data
├── coco2014
│   └── val2014
│       └── ...
├── hadpo
│   └── llava-v1.5
│       ├── desc_data.json
|       └── pope_data.json
├── POPE
│   └── ...
├── shr
│   ├── shr_factual_part1.jsonl
│   ├── shr_factual_part2.jsonl
│   └── val_images_final.json
└── VG
    ├── image_data.json+
    ├── region_descriptions.json
    ├── VG_100K
        └── ...
    └── VG_100K_2
        └── ...
```

### 代码准备

#### DeepSpeed 库介绍

[博客介绍](https://blog.csdn.net/u010751000/article/details/123516433)

[官方文档](https://deepspeed.readthedocs.io/en/latest/)

[配置参数文档](https://www.deepspeed.ai/docs/config-json/)

pytorch, tensorflow, keras 等框架在面向大规模模型编程时不是很方便.

以 pytorch 为例, pytorch 的分布式并行计算框架 (Distributed Data Parallel, 简称 DDP), 仅能使数据并行, 即模型大于显卡显存时, 除非将模型参数拆开到各个 GPU 上, 否则无法使用.

DeepSpeed 是微软开源的框架, 能实现拆散功能, 将模型参数拆散到各个 GPU 上, 实现大模型的计算, 是我们用更少的 GPU 训练更大的模型而不受限于显存. 但是 DeepSpeed 的文档写的不好

载入模型和编写模型的代码基本相同, DeepSpeed 通过输入参数来启动训练, 使用argparse解析参数

#### LLaVA-1.5

##### 更新 Evaluation 代码

由于部分 Evaluation 代码已经更新, 需要手动下载 [eval.zip](https://drive.google.com/file/d/1atZSBBrAX54yYpxtVVW33zFvcnaHeFPy/view?usp=sharing) 放到 `ha_dpo/models/llava-v1_5/playground/data/eval` 路径, 压缩包内的十一个文件夹用作不同测试集.

##### 更新POPE代码

根据 [LLaVA-issue-626](https://github.com/haotian-liu/LLaVA/issues/626), repo 内 [POPE的教程](https://github.com/haotian-liu/LLaVA/blob/main/docs/Evaluation.md#pope) 是对POPE旧版本的指导, 但是代码内已经修改为新版本. LLavA在 [Scripts教程](https://github.com/haotian-liu/LLaVA/blob/main/docs/Evaluation.md#scripts) 内给出 `eval.zip`, 压缩包内含有新版POPE的评估代码与测试集. 按照[此处](更新Evaluation代码)更新测试集和代码即可.




## LLaVA-1.5训练

### `deepspeed` 指令解读

根据[文档](https://github.com/opendatalab/HA-DPO/blob/main/ha_dpo/models/llava-v1_5/README.md#model-training)给出的下述训练指令, 找到 `ha_dpo/models/llava-v1_5/train_dpo.py`. 

```
deepspeed ha_dpo/models/llava-v1_5/train_dpo.py \
    --lora_enable True --lora_r 128 --lora_alpha 256 --mm_projector_lr 0 \
    --deepspeed ha_dpo/models/llava-v1_5/scripts/zero3.json \
    --model_name_or_path liuhaotian/llava-v1.5-7b \
    --version v1 \
    --vg_path ha_dpo/data/VG \
    --desc_data_path ha_dpo/data/hadpo/llava-v1.5/desc_data.json \
    --pope_data_path ha_dpo/data/hadpo/llava-v1.5/pope_data.json \
    --vision_tower openai/clip-vit-large-patch14-336 \
    --mm_projector_type mlp2x_gelu \
    --mm_vision_select_layer -2 \
    --mm_use_im_start_end False \
    --mm_use_im_patch_token False \
    --image_aspect_ratio pad \
    --group_by_modality_length True \
    --bf16 True \
    --output_dir ha_dpo/models/llava-v1_5/checkpoints/{model_name} \
    --num_train_epochs 1 \
    --per_device_train_batch_size 16 \
    --per_device_eval_batch_size 4 \
    --gradient_accumulation_steps 1 \
    --evaluation_strategy "no" \
    --save_strategy "steps" \
    --save_steps 50000 \
    --save_total_limit 1 \
    --learning_rate 2e-6 \
    --weight_decay 0. \
    --warmup_steps 0 \
    --lr_scheduler_type "cosine" \
    --logging_steps 1 \
    --tf32 True \
    --model_max_length 2048 \
    --gradient_checkpointing True \
    --dataloader_num_workers 4 \
    --lazy_preprocess True \
    --report_to wandb \
    --run_name "llava-v1.5" \
    --beta 0.1
```

`deepspeed` 指令后的参数与 `train_dpo.py` 中的 `ScriptArguments`, `DataArguments`, `ModelArguments` 有关, 这里我摘取部分重要参数作解释:


**1. script**

- **lora_enable**: 是否使用 lora 进行训练
- **deepspeed**: deepspeed configuration path
- **bf16**: default=False, bf16 是对 fp32 单精度浮点数截断数据. 8bit 表示指数，7bit 表示小数
- **fp16**: default=False, 是否使用 fp16 权重, 5bit 表示指数，10bit 表示小数. fp16 是半精度浮点数, fp32 是单精度浮点数. fp16 计算更快但精准度更低
- **output_dir**: 训练 checkpoint 保存路径
- **num_train_epochs**: 训练 epoch 次数
- **per_device_train_batch_size**: 每个 device 训练的 batch
- **per_device_eval_batch_size**: 每个 device 测试的 batch
- **gradient_accumulation_steps**: default=4, 梯度累积的steps, 每 N 个batch更新一次参数, 实现类似于相同显存扩大 batch_size 的效果. 这是一种时间换空间的处理方法. [参考博客](https://zhuanlan.zhihu.com/p/595716023)
- **evaluation_strategy**: default=no
- **save_strategy**: 保存策略, default=steps
- **save_steps**: 保存参数的频率, default=-1
- **save_total_limit**: default=1, 被保存的模型的参数的数量
- **learning_rate**: 学习率 2e-6
- **weight_decay**: 
- **warmup_steps**: warmup_steps的数量
- **lr_scheduler_type**: 学习率优化器的种类
- **logging_steps**: 记录日志的频率
- **tf32**: 是否使用 tf32
- **model_max_length**: 句子的最大长度, 少pad多截断
- **gradient_checkpointing**: 是否使用梯度保存点. [博客](https://zhuanlan.zhihu.com/p/602473031), 不保存中间节点的梯度, 在反向传播时重新计算这部分节点的梯度, 是一种用时间换空间的方法.
- **dataloader_num_workers**: dataloader的worker进程数量, 经验设置值是自己电脑/服务器的CPU核心数. worker用来将 batch 取到 RAM 中, 数量为0时 RAM 直接找和取 batch. [博客](https://blog.csdn.net/qq_28057379/article/details/115427052)
- **report_to**: default=wandb, 用于指定要将训练结果和日志报告到的不同日记集成平台
- **run_name**: 跑的模型的名字, 这里要改成自己命名的模型
- **beta**: DPO loss的 beta 值

**2. model**

- **model_name_or_path**: 模型名称/路径, 指向参数文件路径
- **version**: default=v0, 代码内仅区分v0, v5与其他
- **vision_tower**: 属于 linear 层, 在 HA-DPO 代码中要训练
- **mm_projector_type**: projector default linear
- **mm_vision_select_layer**: default=-1 for the last layer
- **mm_use_im_start_end**: instruction tune 时设置为 False
- **mm_use_im_patch_token**: instruction tune 时设置为 False

**3. data**

- **vg_path**: VG数据集路径
- **desc_data_path**: desc_data.json 文件路径
- **pope_data_path**: pope_data.json 文件路径
- **image_aspect_ratio**: default=square
- **group_by_modality_length**: default=False
- **lazy_preprocess**


### `deepspeed` 指令修改 (unfinished)

需要注意的是, HA-DPO 和 LLaVA 都有使用 lora 训练的教程, 我的实验需要在 backbone 和 head 间加入模块训练. 所以我们作出以下调整:


**1. script**

需要指定:

    

不需要指定:

    lora_enable False


**2. model**

需要指定

    

不需要指定

    freeze_backbone False
    tune_mm_mlp_adapter True

**3. data**





### `train_dpo.py` 语法解读

deepspeed 库的代码偏向工程, 这里写一些 Python 里的用法

1. `os.environ` 的使用

    [参考博客](https://blog.csdn.net/happyjacob/article/details/109279118)

    `os.environ` 是一个环境变量的字典. 使用以下代码创建自己的环境变量:

    ```
    os.environ["WANDB_PROJECT"]="ha-dpo"
    ```

2. `local_rank` 指定使用哪个 GPU 

3. `@dataclass` 修饰器

    [参考博客1](https://zhuanlan.zhihu.com/p/59657729), [参考博客2](https://zhuanlan.zhihu.com/p/59658598)

    本质是装饰器, 可以给函数动态地增加功能. 以下是 dataclass 装饰器带来的变化：

    - 无需定义__init__, 将值赋给self，dataclass负责处理它

    - 以更加易读的方式预先定义了成员属性和类型提示. 例如, 能轻松知道 val 是 int 类型

4. `*args` 和 `**kwargs`的用法

    [参考博客](https://blog.csdn.net/GODSuner/article/details/117961990), 详见博客

    *args 表示任何多个无名参数, 本质是一个 tuple

    **kwargs 表示关键字参数, 本质是一个 dict

    同时使用时必须要求 *args 参数列要在 **kwargs 前面 (因为位置参数在关键字参数的前面)

5. `@property` 的用法

    把一个方法变成属性. 可以让调用者写出简短的代码，同时保证对参数进行必要的检查

6. `__len__` 魔法方法

    加入 `def __len__(self)` 方法后, 可以直接使用 `len(class_name)` 来获取一个字符串/列表/...的长度, 返回值取决于该方法的返回值

7. `__getitem__` 魔法方法

    `def __getitem__(self, key)` 方法返回所给键对应的值

8. `isinstance()` 函数

    isinstance(a, str). 如果 a 是 str, 返回 True, 例如 a=2 则返回 False

9. `__call__` 方法

    为了将一个类实例当做函数调用, 我们需要在类中实现 `__call__()` 方法. 也就是要在类中实现如下方法: `def __call__(self, *args)`. 这个方法接受一定数量的变量作为输入


### **train_dpo.py** 代码解读

1. `ModelArguments`, `DataArguments`, `ScriptArguments` 三个类用来接受 deepspeed 指令的参数.

2. `LazySupervisedDataset` 类用以 supervised fine-tuning. 

3. `DataCollatorForSupervisedDataset` 类为 supervised fine-tuning 提供示例

4. `find_all_linear_names` 函数用以找到模型中所有的 linear 层.

5. `make_supervised_data_module` 函数整合 `LazySupervisedDataset` 和 `DataCollatorForSupervisedDataset` 两个类. 

6. `maybe_zero_3` 函数

7. `get_peft_state_maybe_zero_3` 函数

8. `get_peft_state_non_lora_maybe_zero_3` 函数

9. `SaverCallBack` 用以在训练结束时打印出 message 并保存模型参数

    继承自 TrainerCallack, 只有一个新定义方法 on_train_end. 先使用 get_peft_state_non_lora_maybe_zero_3 方法获取 non_lora_state_dict, 然后使用以下代码保存参数
    ```
    torch.save(non_lora_state_dict, os.path.join(args.output_dir, 'non_lora_trainables.bin'))
    ```

10. `setup_llava_model` 方法用以设定 LLaVA 训练时的相关参数, 如是否使用 lora, 是否冻结 backbone.

    - 若在 `os.environ` 环境中没有设置 `LOCAL_RANK`, 设置为默认序号的显卡, 并指定 cuda.
    - 设置好 compute_type 和 bits, 即计算精度和位宽
    - 根据 vision_tower,  加载模型配置, 参数既可以为模型名称, 也可以为具体文件. 此处加载与 model_args.model_name_or_path 有关, 调用 `LlavaLlamaForCausalLM` 类定义 model
    - vision_tower 决定调用 LlavaLlamaForCausalLM 类, 使用方法 LlavaLlamaForCausalLM.from_pretrained 加载 llava 的 backbone 和 head, , tune_mm_mlp_adapter 决定是否训练 mm_projector
    - 根据 freeze_backbone, 设置 backbone, 也即前面得到的 model.model 没有梯度
    - 设置 bits, 设置是否使用梯度累积, 设置是否使用 lora 微调
    - 使用 transformers.AutoTokenizer.from_pretrained 自动分词
    - 根据 model_args.version 设置不同的 pad_token 方法
    - vison_tower 决定使用 model.get_vision_tower() 方法加载 vison_tower. `tune_mm_mlp_adapter` 参数决定了是否微调 变量 mm_projector, 代码如下
    ```
    if model_args.tune_mm_mlp_adapter:
        model.requires_grad_(False)
        for p in model.get_model().mm_projector.parameters():
            p.requires_grad = True
    ```
    - 最后设置一些 args, 返回 model 和 tokenizer

11. `main` 函数为主函数

    - 使用 parser 聚合所有 arguments, 得到 script_args, model_args, data_args 三个设置变量
    - 使用 setup_llava_model 建立模型, 得到 llava_policy 和 tokenizer. 然后 freeze reference model, 设置 llava_ref_model 内的参数没有梯度
    - 使用 make_supervised_data_module 获取数据集
    - 使用 TrainingArguments 初始化训练参数, 使用 LlavaDPOTrainer 初始化 DPO 训练器
    - 使用 `dpo_trainer.train()` 开始训练
    - 




### 模型结构

`ha_dpo/models/llava-v1_5/llava/model` 路径下, 可以看到有 `language_model`, `multimodal_encoder`, `multimodal_projector` 三个文件夹. 

检查发现, 与 `train_dpo.py` 在 `ha_dpo/models/llava-v1_5/llava/train/train.py` 基础上完成, 前者引用了后者的一部分方法


#### language_model 文件夹

`llava_llama.py` 中含有 llava 代码与 head 代码. `LlavaLlamaForCausalLM` 类是 llava, 类中 `self.lm_head` 是 head, head 被定义为一个无偏 linear

文件夹下 `mpt/` 和`llava_mpt.py` 是使用 MPT 作为 LLM 进行微调的代码, 这里我们不需要使用.


### 修改代码 (dev)

#### **llava_llama.py** 文件中加入post progress module

##### LlavaLlamaModel 类

`LlavaLlamaModel` 类定义了 llava 的backbone, 继承自 `LlavaMetaModel` 和 `LlamaModel`, 父类都是 `ha_dpo/models/llava-v1_5/llava/model/llava_arch.py` 定义的类.

在 `LlavaLlamaForCausalLM` 类继承自 `LlamaForCausalLM` 和 `LlavaMetaForCausalLM`. 



该类的初始化与其父类 `LlamaForCausalLM` 相同, 这个类是 transformers 库中的模块

在 `train_dpo.py` 文件中, 以下代码定义了该类的初始化输入

```
model = LlavaLlamaForCausalLM.from_pretrained(
    model_args.model_name_or_path,
    cache_dir=script_args.cache_dir,
    **bnb_model_from_pretrained_args
)
```




## baseline测试

根据 HA-DPO 给出[教程](ha_dpo/models/llava-v1_5/README.md), 进行 Evaluation

### POPE Evaluation

**_step 1._** 输入以下指令, 

```
torchrun --nproc_per_node 1 --master_port $RANDOM ha_dpo/models/llava-v1_5/pope_eval.py \
    --coco_path ha_dpo/data/coco2014 \
    --pope_path ha_dpo/data/POPE \
    --model-path /home/cuiruochen/model/llava-v1.5-7b \
    --model-base liuhaotian/llava-v1.5-7b \
    --set {random/popular/adv}
```

1. ```--set```: validation sets in POPE, choose ```random/popular/adv```. After inference, the answer file will be generated under the folder of LLaVA.
2. ```--model-path```: path to the the trained adapter weights.
3. ```--model-base```: 使用LLaVA-baseline时, 不设置此项, 同时设置```--model-path```为```liuhaotian/llava-v1.5-7b```
4. ```--nproc_per_node1```: 代表使用几张卡. 详见[博客](https://blog.csdn.net/u012605037/article/details/115294898)


在服务器上我使用的指令为:

```
torchrun --nproc_per_node 2 --master_port $RANDOM ha_dpo/models/llava-v1_5/pope_eval.py \
    --coco_path ha_dpo/data/coco2014 \
    --pope_path ha_dpo/data/POPE \
    --model-path /home/cuiruochen/model/llava-v1.5-7b \
    --set popular
```

这一指令执行时间较长, 使用两张3090, 各占用显存15G, 约18min.

**note:** 在LLaVA给出的python==3.10环境中, 在torchrun过程中会报错. 原因未知, 怀疑是llava环境重名产生报错

**单机多卡**

1. 可以使用`CUDA_VISIBLE_DEVICES`指定使用哪几张显卡. 不使用该指令同时指定`nproc_per_node`大于1, 会默认使用序号为 0 到 nproc_per_node-1 的显卡

2. (官方推荐, 可拓展到多机多卡) 在命令指定的 `pope_eval.py` 文件中可以修改来指定使用哪几张显卡. 值得注意的是, 分布式运行指令 `torch.distributed.launch` 已经被遗弃, 现在都使用torchrun, 详情见[官方文档](https://pytorch.org/docs/stable/elastic/run.html). "Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions". 

使用1.的代码如下

```
CUDA_VISIBLE_DEVIOCES=3,4,5,6 torchrun --nproc_per_node 4 --master_port $RANDOM ha_dpo/models/llava-v1_5/pope_eval.py \
    --coco_path ha_dpo/data/coco2014 \
    --pope_path ha_dpo/data/POPE \
    --model-path /home/cuiruochen/model/llava-v1.5-7b \
    --set random
```


**_step2._** 修改answer和label的路径

将 `ha_dpo/data/POPE/evaluate.py` 中的 `ans_file` 设置为第一问中产生回答文件的地址, 一般为 `ha_dpo/models/llava-v1_5` 路径下的某个jsonl文件. `label_file` 设置为 `ha_dpo/data/POPE/output/coco` 下的文件


**_step 3._** 进行测试

运行以下代码获取POPE结果

```
python ha_dpo/data/POPE/evaluate.py
```

使用4卡3090, 得到结果: 

| Model | HA-DPO | Accuracy | Precision | Recall | F1 Score | Yes Ratio (%) |
|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
| LLaVA-1.5-7B | popular | × | 89.62 | 83.28 | 90.67 | 86.82 | 54.43 |
| LLaVA-1.5-7B | popular | √ |  |  |  |  |  |
| LLaVA-1.5-7B | random | × | 89.67 | 88.89 | 90.67 | 89.77 | 51.00 |
| LLaVA-1.5-7B | random | √ |  |  |  |  |  |
| LLaVA-1.5-7B | adversarial | × | 79.73 | 74.40 | 90.67 | 81.73 | 60.93 |
| LLaVA-1.5-7B | adversarial | √ |  |  |  |  |  |










## TODO

1. - [ ] 记得找个女朋友 QWQ
2. 了解代码结构
   1. - [x] train_dpo.py
   2. - [x] large language model 文件夹
3. - [ ] 学习使用 wandb, 在服务器上登录并使用 api 记录
4. - [ ] 查看 LLaVA 的原生 MODEL_ZOO


## maybe useful

[mm_projector issue](https://github.com/haotian-liu/LLaVA/issues/948)







## 几个问题

1. flash-attn 和 xformers

    flash-attn 适合 A100 服务器使用, xformers 适合 RTX4090 使用? 需要寻找资料

2. ZeRO2, ZeRO3, ZeRo_offload

    时间换空间的策略. ZeRO-1是将优化器分片, ZeRO-2是在ZeRO-1的基础上将梯度分片, ZeRO-3是在ZeRO-2的基础上将权重分配训练. 速度 1>2>3>offload

3. 服务器问题
   
   时间不准, 服务器没有 `tree` 环境指令, 没有 `nvitop` 指令

4. 指定使用哪张显卡
   
   [官方](https://github.com/microsoft/DeepSpeed/issues/662) 不建议使用 `CUDA_VISIBLE_DEVICES=1 python -m`, 建议在 deepspeed 阶段使用 `deepspeed --include localhost:1` 来指定显卡

5.  以下 Warning 未解决

    ```
    [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
    ```

6. 模型量化策略 quantization strategies

    模型量化 (Quantization) 是一种用于通过修改权重的精度来减小大型神经网络 (包括大型语言模型) 大小的技术, 尝试从 16-bit 变为  4-bit/8-bit training. [official implement](https://github.com/haotian-liu/LLaVA/issues/1041)

    根据 LLaVA official scripts, 使用 4-bits 进行 inference 的指令为:

    ```
    python -m llava.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-path /home/cuiruochen/model/llava-v1.5-7b
    ```

7. 估计模型参数, [博客](https://blog.csdn.net/weixin_44292902/article/details/133767448)

    | dtype | 每10亿参数 (1B) 需要占用内存 |
    |:--:|:--:|
    | float32 | 4G |
    | fp16 / bf16 | 2G |
    | int8 | 1G |
    | int4 | 0.5G |



## Acknowledge






