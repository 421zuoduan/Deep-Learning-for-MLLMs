# 基于HA-DPO和LLaVA的代码库进行训练和测试

## conda环境搭建

参考[环境配置](/home/cuiruochen/环境配置.md)完成conda环境搭建与配置, 使用以下代码使用环境

```
conda activate llava
```

## git版本管理

**_step1._** vscode 安装 git 相关插件

**_step2._** 用户登录 github 账号

1. 用户账号的主目录下生成 ssh 密钥对

```
ssh-keygen -t rsa -b 4096 -C "your_email@example.com"
```

打开生成的公钥文件, 它的默认位置是 `~/.ssh/id_rsa.pub`, 复制公钥内容. 然后登录 GitHub, 转到 "Settings" -> "SSH and GPG keys" -> "New SSH key", 将公钥粘贴到 "Key" 文本框中, 然后点击 "Add SSH key"

2. 在项目文件夹路径下登录账号 (**note**: 这里没有使用--global, 使用的后果未知)

```
git config --global user.name "Your Name"
git config --global user.email "your_email@example.com"
git config --global core.sshCommand "ssh -i /home/user1/.ssh/id_rsa"
```

确保将 `/home/user1/.ssh/id_rsa` 替换为你生成的私钥的路径

3. 尝试连接github

```
ssh -T git@github.com
```

确认连接后, 会提示 "You've successfully authenticated", 表示登陆成功


**_step3._** 将服务器仓库与远程仓库关联

```
git remote add origin https://github.com/421zuoduan/Deep-Learning-for-MLLMs.git
```

如果已经与远程仓库关联, 使用以下指令查看当前关联的远程仓库

```
git remote -v
```

与原有远程仓库删除关联

```
git remote remove origin
```

此时再执行前述关联新仓库的指令


**_step4._** 设置.gitignore

`.gitignore` 文件用以设置哪些文件夹和文件不需要上传, 具体格式详见该文件


**_step4._** git push

创建测试环境分支 `dev`, 并在服务器上切换为该分支

```
git checkout -b dev
```

由于本地是 git clone 自HA-DPO仓库并进行了修改, 这里不进行 git pull 操作, 强制 push

```
git add .
git commit -m "init"
git push origin dev --force
```

push 过程中经常出现网络连接问题, 尝试使用以下代码取消代理. 如果依然出现 fatal 报错, 等一会再push

```
git config --global --unset http.proxy
git config --global --unset https.proxy
```

经常出现的报错有:

```
fatal: unable to access 'https://github.com/user/project.git/': GnuTLS recv error (-110): The TLS connection was non-properly terminated.
```

或

```
fatal: unable to access 'https://github.com/user/project.git/': Failed to connect to github.com port 443 after 131081 ms: Connection timed out
```


**_step5._** commit 的撤销与删除

commit时如果发现有时间过长或大文件没有gitignore, 可以使用插件`Git Graph`撤销commit

| | 是否删除对代码的修改 | 是否删除commit记录 | 是否新增commit记录 |
|:--:|:--:|:--:|:--:|
| Undo Commit | 不会 | 未Push会, 已Push不会 | 不会 |
| Revert Commit | 会 | 不会 | 会 |
| Drop Commit | 会 | 未Push会, 已Push不会 | 不会 |

按下`Ctrl + Shift + P`, 然后搜索`Git: Undo Last Commit`, 即可撤销上一次的commit

**_step6._** 大文件push后无法解决之究极方法--删除repo和.git文件

1. 删repo

2. 打开vscode的 `File-Preferences-Setting`, 搜索 `Exclude`, 删除 `**/.git`, 即可显示 `.git` 文件夹, 删除.git

## 数据集与代码准备

### 数据集准备

依照[data preparation](ha_dpo/data/data_preparation.md)进行数据集和测试集的准备

数据集结构如下

```
ha_dpo/data
├── coco2014
│   └── val2014
│       └── ...
├── hadpo
│   └── llava-v1.5
│       ├── desc_data.json
|       └── pope_data.json
├── POPE
│   └── ...
├── shr
│   ├── shr_factual_part1.jsonl
│   ├── shr_factual_part2.jsonl
│   └── val_images_final.json
└── VG
    ├── image_data.json+
    ├── region_descriptions.json
    ├── VG_100K
        └── ...
    └── VG_100K_2
        └── ...
```

### 代码准备

#### LLaVA-1.5

##### 更新Evaluation代码

由于部分Evaluation代码已经更新, 需要手动下载[eval.zip](https://drive.google.com/file/d/1atZSBBrAX54yYpxtVVW33zFvcnaHeFPy/view?usp=sharing)放到`ha_dpo/models/llava-v1_5/playground/data/eval`路径, 压缩包内的十一个文件夹用作不同测试集.

##### 更新POPE代码

根据[LLaVA-issue-626](https://github.com/haotian-liu/LLaVA/issues/626), repo内[POPE的教程](https://github.com/haotian-liu/LLaVA/blob/main/docs/Evaluation.md#pope)是对POPE旧版本的指导, 但是代码内已经修改为新版本. LLavA在[Scripts教程](https://github.com/haotian-liu/LLaVA/blob/main/docs/Evaluation.md#scripts)内给出`eval.zip`, 压缩包内含有新版POPE的评估代码与测试集. 按照[此处](更新Evaluation代码)更新测试集和代码即可.




## LLaVA-1.5训练

根据[文档](https://github.com/opendatalab/HA-DPO/blob/main/ha_dpo/models/llava-v1_5/README.md#model-training)给出的下述训练指令, 找到`ha_dpo/models/llava-v1_5/train_dpo.py`. 

```
deepspeed ha_dpo/models/llava-v1_5/train_dpo.py \
    --lora_enable True --lora_r 128 --lora_alpha 256 --mm_projector_lr 0 \
    --deepspeed ha_dpo/models/llava-v1_5/scripts/zero3.json \
    --model_name_or_path liuhaotian/llava-v1.5-7b \
    --version v1 \
    --vg_path ha_dpo/data/VG \
    --desc_data_path ha_dpo/data/hadpo/llava-v1.5/desc_data.json \
    --pope_data_path ha_dpo/data/hadpo/llava-v1.5/pope_data.json \
    --vision_tower openai/clip-vit-large-patch14-336 \
    --mm_projector_type mlp2x_gelu \
    --mm_vision_select_layer -2 \
    --mm_use_im_start_end False \
    --mm_use_im_patch_token False \
    --image_aspect_ratio pad \
    --group_by_modality_length True \
    --bf16 True \
    --output_dir ha_dpo/models/llava-v1_5/checkpoints/{model_name} \
    --num_train_epochs 1 \
    --per_device_train_batch_size 16 \
    --per_device_eval_batch_size 4 \
    --gradient_accumulation_steps 1 \
    --evaluation_strategy "no" \
    --save_strategy "steps" \
    --save_steps 50000 \
    --save_total_limit 1 \
    --learning_rate 2e-6 \
    --weight_decay 0. \
    --warmup_steps 0 \
    --lr_scheduler_type "cosine" \
    --logging_steps 1 \
    --tf32 True \
    --model_max_length 2048 \
    --gradient_checkpointing True \
    --dataloader_num_workers 4 \
    --lazy_preprocess True \
    --report_to wandb \
    --run_name "llava-v1.5" \
    --beta 0.1
```

需要注意的是, HA-DPO和LLaVA都有使用lora训练的教程, 我的实验需要在backbone和head间加入模块训练












## baseline测试

根据HA-DPO给出[教程](ha_dpo/models/llava-v1_5/README.md), 进行Evaluation

### POPE Evaluation

**_step 1._** 输入以下指令, 

```
torchrun --nproc_per_node 1 --master_port $RANDOM ha_dpo/models/llava-v1_5/pope_eval.py \
    --coco_path ha_dpo/data/coco2014 \
    --pope_path ha_dpo/data/POPE \
    --model-path /home/cuiruochen/model/llava-v1.5-7b \
    --model-base liuhaotian/llava-v1.5-7b \
    --set {random/popular/adv}
```

1. ```--set```: validation sets in POPE, choose ```random/popular/adv```. After inference, the answer file will be generated under the folder of LLaVA.
2. ```--model-path```: path to the the trained adapter weights.
3. ```--model-base```: 使用LLaVA-baseline时, 不设置此项, 同时设置```--model-path```为```liuhaotian/llava-v1.5-7b```
4. ```--nproc_per_node1```: 代表使用几张卡. 详见[博客](https://blog.csdn.net/u012605037/article/details/115294898)


在服务器上我使用的指令为:

```
torchrun --nproc_per_node 2 --master_port $RANDOM ha_dpo/models/llava-v1_5/pope_eval.py \
    --coco_path ha_dpo/data/coco2014 \
    --pope_path ha_dpo/data/POPE \
    --model-path /home/cuiruochen/model/llava-v1.5-7b \
    --set popular
```

这一指令执行时间较长, 使用两张3090, 各占用显存15G, 约18min.

**单机多卡**

1. 可以使用`CUDA_VISIBLE_DEVICES`指定使用哪几张显卡. 不使用该指令同时指定`nproc_per_node`大于1, 会默认使用序号为0到nproc_per_node-1的显卡

2. (官方推荐, 可拓展到多机多卡) 在命令指定的`pope_eval.py`文件中可以修改来指定使用哪几张显卡. 值得注意的是, 分布式运行指令`torch.distributed.launch`已经被遗弃, 现在都使用torchrun, 详情见[官方文档](https://pytorch.org/docs/stable/elastic/run.html). "Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions". 

使用1.的代码如下

```
CUDA_VISIBLE_DEVIOCES=3,4,5,6 torchrun --nproc_per_node 4 --master_port $RANDOM ha_dpo/models/llava-v1_5/pope_eval.py \
    --coco_path ha_dpo/data/coco2014 \
    --pope_path ha_dpo/data/POPE \
    --model-path /home/cuiruochen/model/llava-v1.5-7b \
    --set random
```


**_step2._** 修改answer和label的路径

将`ha_dpo/data/POPE/evaluate.py`中的`ans_file`设置为第一问中产生回答文件的地址, 一般为`ha_dpo/models/llava-v1_5`路径下的某个jsonl文件. `label_file`设置为`ha_dpo/data/POPE/output/coco`下的文件


**_step 3._** 进行测试

运行以下代码获取POPE结果

```
python ha_dpo/data/POPE/evaluate.py
```

得到结果: 

popular, 4卡

```
TP      FP      TN      FN
1360    273     1227    140
Accuracy: 0.8623333333333333
Precision: 0.8328230251071648
Recall: 0.9066666666666666
F1 score: 0.8681774656878392
Yes ratio: 0.5443333333333333
```
random, 4卡

```
TP      FP      TN      FN
1360    170     1330    140
Accuracy: 0.8966666666666666
Precision: 0.8888888888888888
Recall: 0.9066666666666666
F1 score: 0.8976897689768976
Yes ratio: 0.51
```

adeversarial, 4卡

```
TP      FP      TN      FN
1360    468     1032    140
Accuracy: 0.7973333333333333
Precision: 0.7439824945295405
Recall: 0.9066666666666666
F1 score: 0.8173076923076923
Yes ratio: 0.6093333333333333
```

**note:** 在LLaVA给出的python==3.10环境中, 在torchrun过程中会报错. 原因未知, 怀疑是llava环境重名产生报错
