!!python/object:__main__.ScriptArguments
auxilary: true
beta: 0.1
ccsbualign_data_path: post_interaction_block/data/cc_sbu_align
cfg_path: post_interaction_block/models/minigpt4/train_configs/minigpt4_llama2_stage3_dpo_post.yaml
ddp_find_unused_parameters: false
desc_train_data_path: post_interaction_block/data/hadpo/minigpt4/desc_data.json
eval_steps: null
evaluation_strategy: 'no'
freeze_llama_proj: true
gamma: 0.5
gradient_accumulation_steps: 16
gradient_checkpointing: false
ignore_bias_buffers: false
learning_rate: 5.0e-06
log_freq: 1
logging_steps: 4
lr_scheduler_type: cosine
max_grad_norm: 1.0
max_length: 1024
max_prompt_length: 512
max_steps: 1000
model_name_or_path: ../sft/results/final_checkpoint
num_train_epochs: -1
optimizer_type: paged_adamw_32bit
output_dir: post_interaction_block/models/minigpt4/minigpt4/output/llama-2-7b-chat-hf-post-20240516-v8-bs-2-1-16-epoch-1-gpu-4-lr-5e-6
per_device_eval_batch_size: 1
per_device_train_batch_size: 2
pope_train_data_path: post_interaction_block/data/hadpo/minigpt4/pope_data.json
report_to: wandb
run_name: minigpt4
save_steps: -1
seed: 42
tune_post_interaction_block: true
vg_path: post_interaction_block/data/VG
warmup_steps: 0
weight_decay: 0.05
